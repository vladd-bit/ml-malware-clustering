from scipy.sparse import csr, csr_matrix
from sklearn.metrics.pairwise import cosine_distances, cosine_similarity, euclidean_distances
from sklearn.model_selection import train_test_split

from src.algorithms.unsupervised import kmeans_existing_dataset, gaussian_mixture, hierarchical_clustering, dbscan, \
    knn_un, optical, birch_clustering
from src.errorLog import Log


class DataClusterer:

    def __init__(self, data=None, labels=None, apk_names=None, clustering_method=None, benign_included=False):
        self.data = data
        self.data_dense = data.toarray() if (benign_included is False and type(data) == csr_matrix) or type(data) == csr_matrix else data
        self.labels = labels
        self.apk_names = apk_names

        self.clustering_method = clustering_method

        self.X_train = None
        self.X_test = None
        self.Y_train = None
        self.Y_test = None

        # stores all labels for all samples
        self.label_numbers, self.family_label_numbers = self.convert_labels_to_numbers()

        # store all distance matrices used for the algorithms
        self.precomputed_distances = None

        # stored in case an algorithm with the same settings has already been computed
        self.already_performed_stats = {}

    """
        Used to compute different distances to samples in the dataset. The distance matrices
         are then stored for use with the clustering algorithms.
    """
    def compute_similarity_distances(self, dataset, disable_distances=False):
        if disable_distances is False:
            self.precomputed_distances = {'euclidean': euclidean_distances(dataset),
                                          'cosine': cosine_distances(dataset),
                                          'cosine_similarity': cosine_similarity(dataset, dense_output=True),
                                          'knn': knn_un(dataset, self.data_dense)}
        else:
            self.precomputed_distances = {'cosine': 0,
                                          'cosine_similarity': 0,
                                          'knn': 0}

    """
        Since the labels stored are actually in string format. We assign a label number to each and convert it
        to an array containing all the labels for each sample.
    """
    def convert_labels_to_numbers(self, labels=None, no_labels_malicious=None, no_labels_bening=None):

        labels_as_numbers = {}

        if labels is None:
            labels = self.labels

        apk_labels = []

        if no_labels_malicious is not None and no_labels_bening is not None:
            apk_labels.extend([0] * no_labels_malicious)
            apk_labels.extend([1] * no_labels_bening)
        elif labels is not None:
            index = 0
            for family_name, apk_list in labels.items():
                labels_as_numbers[family_name] = index

                for apk_name in self.apk_names:
                    if apk_name in apk_list:
                        apk_labels.append(index)

                index = index + 1

        return apk_labels, labels_as_numbers

    """

        Since the labels stored are actually in string format. We assign a label number to each and convert it
        to an array containing all the labels for each sample.
    """
    def perform_unsupervised_clustering(self, data=None, label_numbers=None,
                                            n_clusters=2, non_parallel_algo_only=False,
                                            parallel_algo_only=False):

        if data is None:
            data = self.data

        if label_numbers is None:
            label_numbers = self.label_numbers

        stats = {}

        if non_parallel_algo_only:
            Log.log_message(log_level="INFO", log_message='Clustering for ' + str(n_clusters) + " clusters. Non Parallel algos: hierarhical. Using:" + str(self.clustering_method) + " method(s)")
        elif parallel_algo_only:
            Log.log_message(log_level="INFO", log_message='Clustering for ' + str(n_clusters) + " clusters. Parallel algos: dbscan, birch, k-means. Using:" + str(self.clustering_method) + " method(s)")

        if parallel_algo_only:
            if 'birch' in self.clustering_method or self.clustering_method == 'all':
                stats.update({'BIRCH': birch_clustering(dataset=data,
                                                        dataset_dense=self.data_dense,
                                                        label_numbers=label_numbers, n_clusters=n_clusters,
                                                        )})

            if 'k-means' in self.clustering_method or self.clustering_method == 'all':
                stats.update({'k-means': kmeans_existing_dataset(dataset=data,
                                                                 dataset_dense=self.data_dense,
                                                                 label_numbers=label_numbers, n_clusters=n_clusters,
                                                                 )})

            if 'dbscan' in self.clustering_method or self.clustering_method == 'all':
                if 'dbscan' not in self.already_performed_stats.keys():
                    stats_result = {'dbscan': dbscan(dataset=data,
                                                     label_numbers=label_numbers,
                                                     dataset_dense=self.data_dense,
                                                     n_clusters=n_clusters,
                                                     distance_matrix=self.precomputed_distances['knn']['euclidean']
                                                     )}
                    stats.update(stats_result)
                    #self.already_performed_stats['dbscan'] = stats_result
                else:
                    stats.update(self.already_performed_stats['dbscan'])

            #if 'optics' in self.clustering_method:
            #    stats.update({'optics': optical(dataset=data,
            #                                    dataset_dense=self.data_dense,
            #                                    label_numbers=label_numbers,
            #                                    n_clusters=n_clusters)})

        elif non_parallel_algo_only:
            if 'agglomeration' in self.clustering_method or self.clustering_method == 'all':
                stats.update(
                    {'hierarchical-agglomeration': hierarchical_clustering(dataset=data,
                                                                           label_numbers=label_numbers,
                                                                           dataset_dense=self.data_dense,
                                                                           n_clusters=n_clusters
                                                                           )})
            #if 'gaussian' in self.clustering_method or self.clustering_method == 'all':
            #    stats.update({'gaussian-em': gaussian_mixture(dataset=data, label_numbers=label_numbers,
            #                                                  dataset_dense=self.data_dense,
            #                                                  n_clusters=n_clusters)})

        return stats

    def split_dataset(self, dataset, label_numbers, test_size=0.2):

        self.X_train, self.X_test, self.Y_train, self.Y_test = \
            train_test_split(dataset, label_numbers, test_size=test_size, random_state=0)

    @staticmethod
    def perform_cluster_validation(pred_label_numbers, apk_names, true_label_numbers=None, labels=None):

        cluster_numbers = {}

        for index, cluster_number in enumerate(pred_label_numbers):
            if cluster_number not in cluster_numbers.keys():
                cluster_numbers[cluster_number] = [apk_names[index]]
            else:
                cluster_numbers[cluster_number].append(apk_names[index])

        family_labels_per_cluster = {}

        family_labels_per_cluster_dict = {}

        actual_matches = {}

        correct_predictions = 0

        for sample_label, apks in labels.items():
            for cluster_number, apk_val in cluster_numbers.items():
                for apk in apk_val:
                    if apk in apks:
                        if str(sample_label) + '-' + str(cluster_number) in family_labels_per_cluster.keys():
                            family_labels_per_cluster[str(sample_label) + '-' + str(cluster_number)].append(apk)
                        else:
                            family_labels_per_cluster[str(sample_label) + '-' + str(cluster_number)] = [apk]

                        if sample_label not in family_labels_per_cluster.keys():
                            family_labels_per_cluster_dict[sample_label] = [(apk, cluster_number)]
                        else:
                            family_labels_per_cluster_dict[sample_label].append((apk, cluster_number))

        for virus_label, apks in labels.items():
            cluster_initially_found = None
            for pair in family_labels_per_cluster_dict[virus_label]:
                if pair[0] in apks:
                    if cluster_initially_found is None:
                        cluster_initially_found = pair[1]
                        correct_predictions = correct_predictions + 1
                    elif cluster_initially_found == pair[1]:
                        correct_predictions = correct_predictions + 1

        print(correct_predictions)
