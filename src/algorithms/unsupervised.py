from sklearn import cluster
from sklearn.cluster import FeatureAgglomeration, AgglomerativeClustering, DBSCAN, OPTICS, Birch
from sklearn.mixture import GaussianMixture
from sklearn.neighbors import NearestNeighbors

from src.algorithms.supervised import random_forest
from src.config import CPU_COUNT
from src.util import *


"""
    K-NN used to calcluate the distance matrix
    Returns: distance matrix
"""
def knn_un(dataset, dataset_dense):
    metrics = ['cosine', 'euclidean']
    distances = {}
    for metric_type in metrics:
        nearest_neighbours = NearestNeighbors(n_neighbors=numpy.shape(dataset)[0],
                                              metric=metric_type, algorithm='auto', n_jobs=CPU_COUNT).fit(dataset_dense)
        distance, indices = nearest_neighbours.kneighbors(dataset_dense)

        distances[metric_type] = distance

    return distances

"""
    K-means algorithm settings and implementation
    Returns: stats and predictions
"""
def kmeans_existing_dataset(dataset, dataset_dense, label_numbers, n_clusters=2):

    k_means = cluster.KMeans(n_clusters=n_clusters, algorithm='full', precompute_distances=True,
                             copy_x=True, random_state=False, init='random',
                             n_jobs=CPU_COUNT).fit_predict(dataset)

    stats = [calculate_stats(algorithm_type="k-means", dataset=dataset, dataset_dense=dataset_dense,
                             n_clusters=n_clusters,
                             true_labels=label_numbers,
                             pred_labels=k_means)]
    centroids = {}

    return {'stats': stats, 'predictions': k_means, 'centroids': centroids}

"""
    DBSCAN algorithm settings and implementation
    Returns: stats and predictions
"""
def dbscan(dataset, dataset_dense, label_numbers, n_clusters=2, distance_matrix=0):

    eps_ = 0.5

    if distance_matrix is not 0:
        eps_ = abs(numpy.array(numpy.sort(distance_matrix))[:, 1::].mean())

    stats = []
    predictions = []

    metric = 'euclidean'
    minsamples = int(math.log(numpy.shape(dataset)[0]) + n_clusters - 2) # numpy.shape(dataset)[0] #
    db_scan = DBSCAN(algorithm='auto', eps=eps_, metric=metric, min_samples=minsamples,
                     n_jobs=CPU_COUNT)

    prediction = db_scan.fit_predict(dataset)
    predictions.append(prediction)

    clusters_found = str(len(numpy.unique(predictions)))

    stats.append(calculate_stats(algorithm_type="dbscan" + "|eps=" + str(round(eps_)) + "|metric=" + metric,
                                               # + "|min_samples=" + str(minsamples) + "|n_clusters=" + clusters_found,
                                 dataset=dataset, dataset_dense=dataset_dense,

                                 n_clusters=clusters_found,
                                 true_labels=label_numbers,
                                 pred_labels=prediction))

    return {'stats': stats, 'predictions': predictions}

"""
    BIRCH algorithm settings and implementation
    Returns: stats and predictions
"""
def birch_clustering(dataset, dataset_dense, label_numbers, n_clusters=2):

    stats = []
    birch = Birch(threshold=0.7, branching_factor=150, n_clusters=n_clusters, compute_labels=True, copy=True)

    label_prediction = birch.fit_predict(dataset_dense, y=label_numbers)

    stats.append(
        calculate_stats(algorithm_type="BIRCH",
                        n_clusters=n_clusters, dataset=dataset_dense, dataset_dense=dataset_dense,
                        true_labels=label_numbers,
                        pred_labels=label_prediction))

    return {'stats': stats, 'predictions': label_prediction}

"""
    Agglomeration algorithm settings and implementation with multiple linkages etc.
    Returns: stats and predictions
"""
def hierarchical_clustering(dataset, dataset_dense, label_numbers, n_clusters=2):
    stats = []
    predictions = []

    from malwareClustering import output_directory
    from malwareClustering import cache_folder


    for linkage1 in ['average', 'complete', 'single']:
        agglomerative_clustering = AgglomerativeClustering(  # distance_threshold=distance_matrix.mean(),
            n_clusters=n_clusters,
            memory=output_directory + cache_folder,
            compute_full_tree=True,
            affinity='euclidean',
            linkage=linkage1).fit_predict(dataset_dense, y=label_numbers)

        stat = calculate_stats(algorithm_type="hierarchical-agglomeration|linkage=" + linkage1,
                               n_clusters=n_clusters, dataset=dataset_dense, dataset_dense=dataset_dense,
                               true_labels=label_numbers,
                               pred_labels=agglomerative_clustering)

        stats.append(stat)
        predictions.append(agglomerative_clustering)

    return {'stats': stats, 'predictions': predictions}

"""
    Gaussian-EM algorithm settings and implementation with multiple linkages etc.
    Returns: stats and predictions
"""
def gaussian_mixture(dataset, dataset_dense, label_numbers, n_clusters=2):
    stats = []
    predictions = []

    for covariance_type in ('full', 'tied', 'diag', 'spherical'):
        gaussian_em = GaussianMixture( covariance_type=covariance_type, n_components=n_clusters, init_params='kmeans',
                                       warm_start=True) \
            .fit_predict(dataset_dense, label_numbers)

        stat = calculate_stats(algorithm_type="gaussian-em|covariance=" + covariance_type,
                               n_clusters=n_clusters, dataset=dataset, dataset_dense=dataset_dense,
                               true_labels=label_numbers,
                               pred_labels=gaussian_em)

        predictions.append(gaussian_em)
        stats.append(stat)

    return {'stats': stats, 'predictions': predictions}

"""
    Optical algorithm settings and implementation with multiple linkages etc.
    Returns: stats and predictions
"""
def optical(dataset, dataset_dense, label_numbers, n_clusters=2):
    optic_ = OPTICS(min_samples=n_clusters, n_jobs=CPU_COUNT, metric='cosine').fit_predict(dataset_dense, label_numbers)

    stats = [calculate_stats(algorithm_type="optics",
                             n_clusters=n_clusters, dataset=dataset_dense, true_labels=label_numbers,
                             pred_labels=optic_)]

    return {'stats': stats, 'predictions': optic_}
